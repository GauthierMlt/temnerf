{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data.projectionsdataset import ProjectionsDataset\n",
    "from data.emdataset import EMDataset\n",
    "import matplotlib.pyplot as plt \n",
    "from tifffile import imread\n",
    "from data import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import importlib\n",
    "import warnings\n",
    "# import mrcfile\n",
    "# import astra\n",
    "import torch\n",
    "import os\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/Au_Ag\" \n",
    "projections_path = os.path.join(data_path, \"Serie_3_ali.tif\")\n",
    "angles_path = os.path.join(data_path, \"TiltAngle_ali.txt\")\n",
    "mrc_path = os.path.join(data_path, \"Serie_3.mrc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_channels(mode):\n",
    "    return {\n",
    "        \"1\": 1,  \n",
    "        \"L\": 1,  \n",
    "        \"P\": 1,  \n",
    "        \"RGB\": 3,  \n",
    "        \"RGBA\": 4,  \n",
    "        \"CMYK\": 4,  \n",
    "        \"YCbCr\": 3,  \n",
    "        \"I\": 1,  \n",
    "        \"F\": 1,  \n",
    "    }.get(mode, 1)  \n",
    "\n",
    "\n",
    "def read_angles_file(filepath: str) -> torch.Tensor:\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    return torch.from_numpy( np.array([float(line.strip()) for line in lines], dtype=np.float32) )\n",
    "\n",
    "\n",
    "def estimate_memory(n, size, channels=1, dtype=torch.uint8):\n",
    "\n",
    "    bytes_per_pixel = torch.tensor([], dtype=dtype).element_size()\n",
    "    \n",
    "    memory_per_image = size[0] * size[1] * channels * bytes_per_pixel\n",
    "    \n",
    "    total_memory_bytes = n * memory_per_image\n",
    "    \n",
    "    print( f\"Storing this object uses: {total_memory_bytes / 1024**2} MB of memory\" )\n",
    "\n",
    "def tensor_memory_usage(tensor: torch.Tensor) -> float:\n",
    "    num_elements = tensor.numel()\n",
    "    element_size = tensor.element_size()\n",
    "    total_size_in_bytes = num_elements * element_size\n",
    "    print( f\"Storing this tensor uses: {total_size_in_bytes / 1024**2} MB of memory\" )\n",
    "    \n",
    "def get_vram_info():\n",
    "    total_vram = torch.cuda.get_device_properties(0).total_memory\n",
    "    allocated_vram = torch.cuda.memory_allocated(0)\n",
    "    free_vram = total_vram - allocated_vram\n",
    "    return total_vram, allocated_vram, free_vram"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
